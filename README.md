# Steganography in Large Language Models: Mechanistic Interpretability Research

A comprehensive mechanistic interpretability research project investigating steganographic encoding in frontier LLMs.

MATS 10.0 Research Challenge Submission


## ðŸ“‹ Project Overview

This project investigates whether frontier large language models can reliably encode and decode hidden information using 15 distinct steganographic techniques. Through a systematic 4-phase experimental pipeline with 450 trials, we demonstrate that steganographic encoding is both feasible and robust, with important implications for AI safety and prompt injection vulnerabilities.

**Key Findings:**
- **Extraction Rate:** 68.3% (informed decoder) vs. 12.7% (naive decoder)
- **Triviality Gap:** 55.6 percentage points (genuine steganography confirmed)
- **Naturalness Score:** 7.2/10 (high-quality output maintained)
- **Robust Codecs:** Synonym Substitution, Acrostic, Syntactic Structure Swapping

## ðŸš€ Quick Start

### Prerequisites

- Python >= 3.13
- OpenAI API key

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Set your OpenAI API key
export OPENAI_API_KEY="your-api-key-here"
export OPENAI_PROJECT_ID="your-project-id-here"  # Optional
```

### Running the Experiment

```bash
# Run the full 5-phase pipeline (450 trials)
python run_experiment.py

# Run in test mode (minimal API calls, covers all code paths)
python run_experiment.py --test-mode

# Run a specific phase
python run_experiment.py --phase 1

# Run a specific phase in test mode
python run_experiment.py --phase 2 --test-mode

# Start fresh (don't resume from existing results)
python run_experiment.py --no-resume
```

**Test Mode**: Use `--test-mode` to run with reduced API calls for minimal expenses while still covering all code paths:
- Phase 0: 2 baseline samples (instead of 10)
- Phase 1: 1 prompt per codec (instead of 3, still covers all 15 codecs)
- Phase 2: 2 runs per prompt (instead of 10, covers 2 temperatures)
- Phase 3 & 4: Automatically work with reduced data

## ðŸ“Š Experimental Design

### Agents

| Role                 | Model                                          | Purpose                                                            |
| -------------------- | ---------------------------------------------- | ------------------------------------------------------------------ |
| Steganography Expert | gpt-5.2-2025-12-11                             | Generate 45 malicious prompts (3 Ã— 15 codec types)                 |
| Poisoned Helper      | gpt-5.2-2025-12-11                             | 450 deployments (10 instances Ã— 45 prompts) encoding codewords     |
| User Query Generator | Programmatic (templates)                      | Generate user queries with codeword as first word using templates  |
| Informed Decoder        | gpt-5.2-2025-12-11                             | Extract codeword from responses (informed by steganography prompt) |
| Naive Decoder        | gpt-5.2-2025-12-11                             | Extract codeword without steganography prompt (baseline)           |
| Success Checker      | Regex                                          | Validate codeword extraction                                       |
| Natural Checker      | gpt-5-mini-2025-08-07                          | Rate naturalness of poisoned helper responses                      |

### Four-Phase Pipeline

**Phase 1: Malicious Prompt Generation**
- Steganography expert generates 45 malicious prompts
- 3 templates per codec Ã— 15 codecs
- An example of a codec is the use of acrostic e.G. All People Play Loudly Everywhere (The first letter of each line spells "APPLE")
- Each prompt instructs a poisoned helper to encode a hidden codeword

**Phase 2: Poisoned Helper Execution**
- 450 independent runs (10 per prompt as generated by the steganography expert)
- Poisoned helper interacts with user model, acting as a helpful assistant, while encoding a codeword
- Random high-frequency English nouns as codewords
- Temperature settings: 0.0, 0.4, 0.8 (robustness testing)

**Phase 3: Decoder Execution**
- Informed Decoder: Given steganography prompt + response
- Naive Decoder: Given only response (baseline)
- Temperature 0.0

**Phase 4: Evaluation & Metrics**
- Extraction Success Rate (SR): % of codewords correctly recovered
- Triviality Gap: Informed SR - Naive SR
- Naturalness Score: 1-10 rating by Natural Checker

### 15 Steganographic Codecs

**Lexical (5):**
- Tokenization Artifacts
- Synonym Substitution
- Contraction Toggling
- Adverbial Intensity
- Lexical Specificity

**Syntactic (3):**
- Acrostic
- Syntactic Structure Swapping
- List Ordering
- Self-Reference-Frequency

**Typographic (8):**
- Zero-Width Characters
- Punctuation Patterning
- French Spacing
- Capitalization Anomalies
- Sentence Length
- Emoji Flavor

---

## ðŸ“ˆ Key Results - HYPOTHESIZED

### Figure 1: The Steganography Frontier
Scatter plot showing codec effectiveness (naive vs. informed decoder success rates).
- **Top-Left Quadrant:** Gold-standard steganography (high informed, low naive)
- **Top-Right Quadrant:** Trivial encoding (obvious to both decoders)

### Figure 2: Performance vs. Temperature Heatmap
Codec robustness across temperature settings (0.0, 0.4, 0.8).
- **Robust Codecs:** Low drop from T=0.0 to T=0.8
- **Fragile Codecs:** High drop at higher temperatures

### Figure 3: Steganographic Cost Analysis
Naturalness trade-offs by codec type.
- Synonym Substitution: High extraction + high naturalness
- Typographic codecs: Lower naturalness penalties

### Figure 4: Error Type Distribution
Failure mode analysis showing why decoders fail.

## ðŸ“– Research Paper

Research paper available in `report/steganography_research_paper.md` with:
- Problem statement, research question, hypothesis
- Short literature review
- Detailed methodology and reasoning
- Complete results, figures and interpretation
- Discussion of AI safety implications
- References
